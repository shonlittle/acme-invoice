# Invoice Processing Prototype

## Quick Start

### 1. Setup Virtual Environment

```bash
python3 -m venv venv
source venv/bin/activate  # On macOS/Linux
# OR
venv\Scripts\activate  # On Windows
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Initialize Database

```bash
python3 db/inventory.py
```

### 4. Run Pipeline

```bash
# Single invoice
python3 main.py --invoice_path=data/invoices/invoice_1004.json

# All samples
python3 scripts/run_samples.py

# Tests
python3 -m pytest tests/ -v
```

---

## Implemented Features

### 4-Stage Pipeline

- ✅ **Ingestion** - JSON, CSV, TXT, PDF support
- ✅ **Validation** - SQLite inventory checking (4 rules)
- ✅ **Approval** - Rule-based policy + reflection/critique loop
- ✅ **Payment** - Mock payment with strict gating

### Key Capabilities

- **Structured Logging** - Observable at every stage
- **Deterministic Testing** - 24 unit tests (all passing)
- **Graceful Degradation** - Never crashes, returns minimal data on error
- **Optional LLM Integration** - Grok via xAI API (falls back to mock)
- **Audit Trail** - Full provenance tracking and confidence scores

---

## PDF Ingestion Limitations

PDF invoice processing uses best-effort text extraction:

- **Layout/Formatting Loss:** PDF text extraction does not preserve visual layout, tables, or complex formatting
- **Digital Text Only:** OCR (image-to-text) is out of scope - PDFs must contain extractable text
- **Lower Confidence:** All PDF-extracted fields are marked with reduced confidence scores
- **Library Required:** Requires `PyPDF2` (installed via `requirements.txt`)

If PDF extraction fails or yields empty text, the pipeline continues with a minimal invoice and clear warnings.

---

## Architecture

```
main.py (CLI)
└── pipeline/runner.py (orchestrator)
    ├── agents/ingest.py    (JSON/CSV/TXT/PDF → Invoice)
    ├── agents/validate.py  (Invoice → ValidationFindings)
    ├── agents/approve.py   (Findings → ApprovalDecision)
    └── agents/pay.py       (Decision → PaymentResult)
```

---

## Testing

```bash
# All tests
python3 -m pytest tests/ -v

# Specific test files
python3 -m pytest tests/test_ingestion.py -v
python3 -m pytest tests/test_validation.py -v
python3 -m pytest tests/test_approval.py -v
python3 -m pytest tests/test_payment.py -v
```

---

<!-- DO NOT CHANGE: Original README content below this line -->
<!-- This section is the original project specification and should be preserved as-is -->

# Galatiq Case: Invoice Processing Automation

## Background

Acme Corp is a PE-backed manufacturing firm losing **$2M/year** on manual invoice processing. Invoices arrive via email as PDFs in messy formats with frequent errors. Staff manually extract data, validate against a legacy inventory database (inconsistent), obtain VP approval (via email chains), and process payment (via a banking API).

**Current pain points:**

- 30% error rate
- 5-day processing delays
- Frustrated stakeholders

## Objective

Build a **multi-agent system** that automates the end-to-end invoice processing workflow. The system must run as a working prototype — not just designs or slides.

## Workflow

The system should handle four stages:

1. **Ingestion** — Extract structured data from invoice documents (PDFs, text files). Fields include: Vendor, Amount, Items (with quantities), and Due Date. Expect unstructured text, typos, missing data, and potentially fraudulent entries.

2. **Validation** — Verify extracted data against a mock inventory database (SQLite). Flag mismatches such as quantity exceeding available stock or items not found in inventory.

3. **Approval** — Simulate VP-level review with rule-based decision-making (e.g., invoices over $10K require additional scrutiny). The agent should reason through approval/rejection with a reflection or critique loop.

4. **Payment** — If approved, call a mock payment function. If rejected, log the rejection with reasoning.

## Technical Requirements

- **LLM Integration**: Use xAI's Grok as the core reasoning engine (via the xAI API at https://grok.x.ai). Other models are acceptable if you don't have an API key.
- **Multi-Agent Orchestration**: Use a framework such as LangGraph, CrewAI, AutoGen, or a custom solution.
- **Agent Capabilities**: Function calling / tool use, structured outputs, and self-correction loops.
- **Runtime**: Assume no internet for external APIs — simulate everything locally.
- **Tech Stack**: Python (preferred), with libraries like `langchain`, `crewai`, `autogen`, `pdfplumber`, `PyMuPDF`, etc. Run locally — no cloud deployment.

## Provided Resources

### Mock Invoice Data

Sample invoices are provided in the `data/invoices/` directory in various formats (PDF, CSV, JSON, TXT). Use these as inputs for testing. The data intentionally includes a mix of clean entries and problematic ones — identifying and handling issues is part of the challenge.

### Mock Inventory Database (Required Setup)

Before running the system, you **must** create a local SQLite database that the validation agent will check invoices against. The sample invoices in `data/invoices/` reference specific items and quantities — your database needs to contain matching inventory records so the validation stage can flag mismatches, out-of-stock items, and unknown products.

Below is a starter schema and seed data that covers the core items referenced across the provided invoices:

```python
import sqlite3

conn = sqlite3.connect('inventory.db')  # Persist to file so all agents can access it
cursor = conn.cursor()

cursor.execute('CREATE TABLE IF NOT EXISTS inventory (item TEXT PRIMARY KEY, stock INTEGER)')
cursor.execute("""
    INSERT INTO inventory VALUES
    ('WidgetA', 15),
    ('WidgetB', 10),
    ('GadgetX', 5),
    ('FakeItem', 0)
""")
conn.commit()
```

**Why this matters:** The sample invoices are designed to test your validation logic against this database. For example:

| Scenario                     | Invoice                                                 | What should happen                                |
| ---------------------------- | ------------------------------------------------------- | ------------------------------------------------- |
| Normal order within stock    | INV-1001, INV-1004, INV-1006                            | Items found, quantities valid — passes validation |
| Quantity exceeds stock       | INV-1002 (requests 20× GadgetX, only 5 in stock)        | Flagged as stock mismatch                         |
| Fraudulent / zero-stock item | INV-1003 (references FakeItem, 0 stock)                 | Flagged as out of stock or suspicious             |
| Item not in database at all  | INV-1008 (SuperGizmo, MegaSprocket), INV-1016 (WidgetC) | Flagged as unknown item                           |
| Invalid data                 | INV-1009 (negative quantity)                            | Flagged as data integrity issue                   |

You may extend the seed data with additional items or columns (e.g., unit price, category) to support richer validation — the above is the minimum needed to exercise the provided test invoices. If you want your system to also validate pricing or vendor information, consider adding tables for those as well.

### Mock Payment API

```python
def mock_payment(vendor, amount):
    print(f"Paid {amount} to {vendor}")
    return {"status": "success"}
```

### Grok API Setup

```python
from xai import Grok

client = Grok(api_key="your_key")
response = client.chat.completions.create(
    model="grok-3",
    messages=[{"role": "user", "content": "Reason about this..."}]
)
```

## Running the System

The system should be executable from the command line:

```bash
python main.py --invoice_path=data/invoices/invoice1.txt
```

Output should include structured logs and results.

## Evaluation Criteria

- **Functionality** — Does the system work end-to-end?
- **Code Quality** — Clean, testable, well-structured code with error handling and observability
- **Agentic Sophistication** — LLM integration, multi-agent flow, tool use, self-correction loops
- **Shipping Mindset** — Valuable MVP delivered under ambiguity; scope ruthlessly cut where needed
- **Presentation** — Clear translation of technical decisions to business impact
- **Above/Beyond** - Have you made it your own? Implemented additional features that make the solution feel great? Expanded assumptions? Added to test cases?
- **UI/UX** - Users will understand and enjoy using this system.
